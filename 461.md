# 461_Notes - Querying SQL Server #
**Current Status - Page No : 226** 
* Check the differences between CONVERT, CAST, PARSE. Also check the TRY_ versions of the same.
* Try to Answer Qs in Sql Query Form in Technet (in your T-sql Bookmarks)
* Revisit page 42,43 after completing Chapters 11 and 15
* Try to understand Corelated Sub-Queries properly (pages from 119)
* Practice PIVOT and UNPIVOT Queries.
* For more detailed information about window functions, their optimization, and practical uses, refer to the book Microsoft SQL Server 2012 High-Performance T-SQL Using Window Functions, by Itzik Ben-Gan (Microsoft Press, 2012).
* check how this can be correct : "The RANK function returns one more than the number of rows that have a lower
ordering value than the current"
* SELECT, FROM, WHERE, GROUP BY, HAVING, ORDER BY, TOP, and OFFSET-FETCH. Identify the order in which these clauses are conceptually evaluated according to logical query processing. Also, identify the clauses in which the PIVOT and UNPIVOT operators operate. Finally, identify the clauses in which group functions are allowed and the clauses in which window functions are allowed.
 
##Chapter 1 (Foundations of Querying)##
* Here is the logical query processing order of the six main query clauses:
 * FROM
 * WHERE
 * GROUP BY
 * HAVING
 * SELECT
 * ORDER BY

* Date Time Columns can be queried like this:
WHERE hiredate >= '20030101'
* ORDER BY clause is the first and only clause (Top/Distinct?) that is allowed to refer to column
aliases defined in the SELECT clause. That’s because the ORDER BY clause is the only one
to be evaluated after the SELECT clause
* You cannot use ORDER BY on columns that have the text, ntext, image, or xml data types.
* One of most typical mistakes that T-SQL developers make is to assume that a query without an ORDER BY clause always returns the data in a certain order—for example, clustered index order. But if you understand that in set theory, a set has no particular order to its elements, you know that you shouldn’t make such assumptions. The only way in SQL to guarantee that the rows will be returned in a certain order is to add an ORDER BY clause. That’s just one of many examples for aspects of T-SQL that can be better understood if you understand the foundations of the language. Now, you know that why a view created with an order by clause, does not guarantee any order when we query it with out an order by clause.

##Chapter 2 (Getting Started with SELECT Statement)##
* There are a number of supported forms of aliasing: <expression> AS <alias>
as in empid AS employeeid, <expression> <alias> as in empid employeeid, and <alias> =
<expression> as in employeeid = empid
* If a Table name starts with a numeric value(or has an embedded space, or is a reserved T-SQL
keyword), then delimiters ("" or []) should be used while querying it.
* Float and Real are the datatypes with Maximum Range of values in numbers. But they are not recommended when we need accurate values. Accuracy takes a hit while using these data types.
* Fixed types use the storage for the indicated size; for example, CHAR(30) uses storage for 30 characters, whether
you actually specify 30 characters or less. This means that updates will not require the row to physically expand, and therefore no data shifting is required. So for attributes that get updated frequently, where the update performance is a priority, you should consider fixed types. Note that when compression is used—specifically row compression—SQL Server stores fixed types like variable ones, but with less overhead.
* With character strings, there’s also the question of using regular character types (CHAR,VARCHAR) vs. Unicode types (NCHAR, NVARCHAR). The former use 1 byte of storage per character and support only one language (based on collation properties) besides English. The latter use 2 bytes of storage per character (unless compressed) and support multiple languages.
* You also want to make sure that when indicating a literal of a type, you use the correct form. For example, literals of regular character strings are delimited with single quotation marks, as in 'abc', whereas literals of Unicode character strings are delimited with a capital N and then single quotation marks, as in N'abc'.
* As for the difference between CAST, CONVERT, and PARSE, with CAST, you indicate the expression and the target type; with CONVERT, there’s a third argument representing the style for the conversion, which is supported for some conversions, like between character strings and date and time values. For example, CONVERT(DATE, '1/2/2012', 101) converts the literal character string to DATE using style 101 representing the United States standard. With PARSE, you can indicate the culture by using any culture supported by the Microsoft .NET Framework. For example, PARSE('1/2/2012' AS DATE USING 'en-US') parses the input literal as a DATE by using a United States English culture.
* When using expressions that involve operands of different types, SQL Server usually converts the one that has the lower data type precedence to the one with the higher. Consider the expression 1 + '1' as an example. One operand is INT and the other is VARCHARINT precedes VARCHAR; hence, SQL Server implicitly converts the VARCHAR value '1' to the INT value 1, and the
result of the expression is therefore 2 and not the string '11'.
* Nonsequential GUIDs: You can generate nonsequential global unique identifiers to be stored in an attribute of a UNIQUEIDENTIFIER type. You can use the T-SQL function NEWID to generate a new GUID.
* Sequential GUIDs: You can generate sequential GUIDs within the machine by using the T-SQL function NEWSEQUENTIALID.
* using functions in JOIN (ON) clause will not use indexes properly so avoid them . Example: instead of using ISNULL(A.Col1, -1) = ISNULL(B.Col1, -1) , use A.Col1 = B.Col1 OR (A.Col1 IS NULL AND B.Col1 IS NULL). Another Example is to use LIKE 'ABC%' instead of LEFT(Col,3)='ABC'. However, remember LIKE '%ABC%' will not use Index. Only LIKE 'ABC%' does.
* While doing a SELECT ISNULL(Col1,'') as A, COALESCE(Col1,'') as B INTO ,if the source attribute 'col1' is defined as allowing NULLs, COALESCE will create a result attribute allowing NULLs, whereas ISNULL will create one that disallows NULLs.
* NULLIF function accepts two input expressions, returns NULL if they are equal, and returns the first input if they are not.
* The expression CHOOSE(2, 'x', 'y', 'z') returns 'y'. Again, it’s straightforward to replace a CHOOSE expression with a logically equivalent CASE expression; but the point in supporting CHOOSE, as well as IIF, is to simplify migrations from Access to SQL Server as a temporary solution.
* The + operator by default yields a NULL result on NULL input, whereas the CONCAT function treats NULLs as empty strings.
* DATEFROMPARTS() is new function in SQL Server 2012. Absent in 2008.
* Use REPLICATE function to pad repetitive text.
* Understand FORMAT() function correctly and look at Question 2 in Page54-55
* There are two kinds of CASE() Expressions. SIMPLE and SEARCHED. 
* To improve the portability of the code, it’s important to use standard code when possible, and this of course applies more specifically to the use of built-in functions. For example, use COALESCE and not ISNULL, use CURRENT_TIMESTAMP and not GETDATE, and use CASE and not IIF
* Data Type Precedence https://msdn.microsoft.com/en-us/library/ms190309.aspx
* Date Time Functions https://msdn.microsoft.com/en-us/library/ms186724
* String Functions https://msdn.microsoft.com/en-us/library/ms181984

##Chapter 3 (Filtering and Sorting Data)##
* Country = 'USA' gives all records having USA as Country. Country <> 'USA' does not give all other records. It will eliminate records where Country IS NULL. THis is because the logic is Three way (TRUE, FALSE, UNKNOWN) and only TRUE records are passed. the soultion is to use Country <> 'USA' OR Country IS NULL 
* Negation of true and false is straightforward—NOT true is false, and NOT false is true. What can be surprising to some is what happens when you negate unknown—NOT unknown is still unknown.
*  The NOT operator precedes AND and OR, and AND precedes OR (like BODMAS for Numbers). Parentheses have the highest precedence among all operators
*  THEORY: Unless precedence rules dictate otherwise, predicates will be evaluated from left to right, and that short circuiting will take place when possible. In other words, if the Where Cond is Country = 'USA' AND Region = 'WA', if Country is not USA, the query will not check for Region. REALITY: The reality, though, is different. SQL Server does internally support a short-circuit concept; however, due to the all-at-once concept in the language, it is not necessarily going to
evaluate the expressions in left-to-right order. It could decide, based on cost-related reasons, to start with the second expression, and then if the second expression evaluates to true, to evaluate the first expression as well.
*  It’s a very typical bad habit to specify a regular character string literal when the filtered column is of a Unicode type. Example: Country = 'USA' instead of using Country = N'USA' when country is NVARCHAR. SQL Server implicitly converts one
operand’s type to the other. In this example, fortunately, SQL Server converts the literal’s type to the column’s type, so it can still efficiently rely on indexing.
*  If you want to look for a character that is considered a wildcard, you can indicate it after a character that you designate as an escape character by using the ESCAPE keyword.
*  the form '20070212' is always interpreted as ymd, regardless of your language (English(mdy), UK(dmy), Japanese(ymd)).
*  Note that the form '2007-02-12' is considered language-neutral only for the data types DATE, DATETIME2, and DATETIMEOFFSET. Unfortunately, due to historic reasons, this form is considered language-dependent for the types DATETIME and SMALLDATETIME.
* WHERE orderdate BETWEEN '20080211' AND '20080212 23:59:59.999'; Because 999 is not a multiplication of the DATETIME type’s precision unit (three and a third milliseconds), the end value in the range gets rounded to the next midnight, and the result includes rows from February 13 that you didn’t ask for.
* you can order the result rows by elements that are not part of the SELECT list, as long as the result rows would have normally been allowed there. So due to this reason, for Distinct and Group BY Clauses, we cannot use columns that are not in select clause, in the ORDER BY CLause
* Standard SQL says that NULLs should sort together, but leaves it to the implementation to decide whether to sort them before or after non-NULL values. In SQL Server the decision was to sort them before non-NULLs (when using an ascending direction). Standard SQL supports the options NULLS FIRST and NULLS LAST to control how NULLs sort, but T-SQL doesn’t support this option.
* According to standard SQL, a query with an ORDER BY clause conceptually returns a cursor and not a relation. So remember, a query without an ORDER BY clause returns a relational result (at least froman ordering perspective), and hence doesn’t guarantee any order.
* TOP() function is applied after Order By. So the order is DISTINCT, ORDER BY , TOP. the function takes BIGINT as input parameter. PERCENT When used along with TOP will give top N % of rows. 
* One option is to ask to include all ties with the last row (while using ORDER BY) is by adding the WITH TIES option along with TOP. TOP N WITH TIES can return more than N Records.  
* TOP option can also be used in modification statements to limit how many rows get modified
* The OFFSET-FETCH option is a filtering option that, like TOP, you can use to filter data based on a specified number of rows and ordering. But unlike TOP, it is standard, and also has a skipping capability, making it useful for ad-hoc paging purposes. OFFSET 50 ROWS FETCH NEXT 25 ROWS ONLY; OFFSET 0 ROWS FETCH FIRST 25 ROWS ONLY; observe why First and Next are used appropriately in the two statements. ROW or ROWS both will work in this statment and no errors will be thrown.
* in T-SQL, the OFFSET-FETCH option requires an ORDER BY clause to be present. Also, in T-SQL—contrary to standard SQL—a FETCH clause requires an OFFSET clause to be present. however, the OFFSET clause doesn’t require a FETCH clause.
*  the OFFSET-FETCH option requires an ORDER BY clause. But what if you need to filter a certain number of rows based on arbitrary order? To do so, you can specify the expression (SELECT NULL) in the ORDER BY clause.
*  TOP and OFFSET-FETCH cannot be combined in the same query

##Chapter 4 (Combining Sets)##
* CROSS JOIN is a Cartesian Product. It does not have ON Clause.
* SQL Server knows that with a cross join followed by a filter it can evaluate the filters first (which is especially efficient when there are indexes to support the filters), and then match the remaining rows.
* in addition to supporting the syntax for cross joins with the CROSS JOIN keywords, both standard SQL and T-SQL support an older syntax where you specify a comma between the table names, as in FROM T1, T2. But, Refrain from using it.
* SQL Server automatically creates indexes on Primary Key Columns but doesnt do that for Foriegn keys. So, while doing performance tuning, it is recomended to check if we can create indexes on Foriegn Key columns. 
* What’s the difference between the ON and the WHERE clauses, and does it matter if you specify your predicate in one or the other? The answer is that for inner joins it doesn’t matter.
* While using Outer Joins, Where clause filter applies to values which are coming out of ON clause and not the origional Values in the source table. this is the reason we use WHere col1 IS NULL after left join to find out if column1 does not have a match in Left table. Similarly if we use multiple JOINS, the JOINS used after Outer Joins should be looked at carefully as the NULLS from LEFT JOIN will be passed over to subsequent joins and the origional values will not be passed.
* Refer to Page 113 to properly frame Multiple Joins.
* Multi-join queries involve multiple joins. They can have a mix of different join types.You can control the logical join ordering by using parentheses or by repositioning the ON clauses.
* Subqueries can be self-contained—namely, independent of the outer query; or they can be correlated—namely, having a reference to a column from the table in the outer query. In terms of the result of the subquery, it can be scalar, multi-valued, or table-valued.
* As a predicate, EXISTS doesn’t need to return the result set of the subquery; rather, it returns only true or false, depending on whether the subquery returns any rows. For this reason, the SQL Server Query Optimizer ignores the SELECT list of the subquery, and therefore, whatever you specify there will not affect optimization choices like index selection.
* if the inner query uses the TOP or OFFSET-FETCH option, it’s allowed to have an ORDER BY clause as well (otherwise, it is not). But then the outer query has no presentation ordering guarantees if it doesn’t have its own ORDER BY clause.
* It’s important to note that, from a performance standpoint, when SQL Server optimizes queries involving table expressions, it first unnests the table expression’s logic, and therefore interacts with the underlying tables directly. It does not somehow persist the table expression’s result in an internal work table and then interact with that work table. This
means that table expressions don’t have a performance side to them—neither good nor bad—just no side.
* The thing with the ROW_NUMBER function—and window functions in general—is that they are only allowed in the SELECT and ORDER BY clauses of a query.
* Two column aliasing options are available to you when working with derived tables: inline and external(page 124).
* T-SQL supports four kinds of table expressions, which are named query expressions. Derived tables and CTEs are types of table expressions that are visible only in the scope of the statement that defined them. Views and inline table-valued functions are reusable table expressions whose definitions are stored as objects in the database. Views
do not support input parameters, whereas inline table-valued functions do.
* CROSS APPLY and CROSS JOIN Both return the same result when there’s no correlation between left and right parts because CROSS APPLY applies all rows from Left table to each row from Right Table.
* Set operators (UNION, EXCEPT etc) consider two NULLs as equal for the purpose of comparison. This is quite unusual when compared to filtering clauses like WHERE and ON.
* set operators have precedence: INTERSECT precedes UNION and EXCEPT, and UNION and EXCEPT
* UNION, INTERSECT, EXCEPT return only DISTINCT rows.
* Regarding Using UNION ALL instead of UNION to improve performance, adding CHECK constraints that define the ranges supported by each table can help the optimizer realize that the sets are disjoint. Then, even when using UNION, the optimizer
can realize it doesn’t need to remove duplicates.

##Chapter 5 (Grouping and Windowing)##
* Note that the DISTINCT option is available not only to the COUNT function, but also to other general set functions. However, it’s more common to use it with COUNT.
* COUNT(1) and COUNT(*) has no difference at all. They are identical. COUNT(1) and COUNT(Col1) differ in a way that the latter does not include NULLS while counting.
* GROUPING and GOUPING_ID Functions are helpfull while having NULL values while using ROLLUP/CUBE/GROUPING SETS.
* the clause CUBE(a, b, c) defines eight grouping sets and the clause ROLLUP(x, y, z) defines four grouping sets. By specifying a comma between the two, as in CUBE(a, b, c), ROLLUP(x,y, z), you multiply them and get 32 grouping sets.
* If you look carefully at the specification of the PIVOT operator, you will notice that you indicate the aggregation and spreading elements, but not the grouping element. The grouping element is identified by elimination—it’s what’s left from the queried table besides the aggregation and spreading elements. This is why it is recommended to prepare a table expression
for the pivot operator returning only the three elements that should be involved in the pivoting task. If you query the underlying table directly , all columns from the table besides the aggregation and spreading  columns will implicitly become your grouping elements.
* The COUNT(*) function isn’t allowed as the aggregate function used by the PIVOT operator. If you need a count, you have to use the general COUNT(<col name>) aggregate function.
* A PIVOT operator is limited to using only one aggregate function.
* The IN clause of the PIVOT operator accepts a static list of spreading values. It doesn’t support a subquery as input. You need to know ahead what the distinct values are in the spreading column and specify those in the IN clause. When the list isn’t known ahead, you can use dynamic SQL to construct and execute the query string after querying the distinct values from the data.
* The aggregation and spreading elements cannot directly be results of expressions; instead, they must be column names from the queried table. You can, however, apply expressions in the query defining the table expression, assign aliases to those expressions, and then use the aliases in the PIVOT operator.
* Group Functions work for a GROUP BY CLAUSE and return result for each distinct GROUP BY Clause combinations. WINDOW Functions work for OVER Clause and return values for each row. 
* Window aggregate functions are the same as the group aggregate functions (for example, SUM, COUNT, AVG, MIN, and MAX), except window aggregate functions are applied to a window of rows defined by the OVER clauseOne of the benefits of using window functions is that unlike grouped queries, windowed queries do not hide the detail—they return a row for every underlying query’s row.
* Understand Framing options available for Window aggregate functions.
* Using window aggregate functions to perform computations such as running totals, you typically get much better performance compared to using joins or subqueries and group aggregate functions. Window functions lend themselves to good optimization—especially when using UNBOUNDED PRECEDING as the first delimiter.
* In terms of logical query processing, a query’s result is achieved when you get to the SELECT phase—after the FROM, WHERE, GROUP BY, and HAVING phases have been processed. Because window functions are supposed to operate on the underlying query’s result set, they are allowed only in the SELECT and ORDER BY clauses. So, the gist is, in case of group by (which is used by Group functions), you have HAVING clause which can filter out records. But, in case of window function you have to put the result in a table expression and filter out those records using a seperate WHERE clause. 
* In SQL Server 2012, the ROWS option usually gets optimized much better than RANGE when using the same delimiters. If you define a window with a window order clause but without a window frame clause, the default is RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW. Therefore, unless you are after the special behavior you get from RANGE that includes peers, make sure you explicitly use the ROWS option.
* The ORDER BY Clause present in the window function will have no impact on the actual order that will be present in the result set.
* NTILE does not provide the percentile value. check the definition properly. It actually splits the number of tiles defined, across the result set.
* window offset functions: LAG, LEAD, FIRST_VALUE, and LAST_VALUE
* LEAD and LAG do not support frames (Rows/Range). FIRST_VALUE and LAST_VALUE do. Even for functions like SUM(), frames come into picture when we specify the order by clause. 
* when a window frame is applicable to a function but you do not specify an explicit window frame clause, the default is RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW. For performance reasons, it is generally recommended to avoid the
RANGE option; to do so, you need to be explicit with the ROWS clause. Also, if you’re after the first row in the partition, using the FIRST_VALUE function with the default frame at least gives you the correct result. However, if you’re after the last row in the partition, using the LAST_VALUE function with the default frame won’t give you what you want because
the last row in the default frame is the current row. So with the LAST_VALUE, you need to be explicit about the window frame in order to get what you are after. And if you need an element from the last row in the partition, the second delimiter in the frame should be UNBOUNDED FOLLOWING.
* check example of using LAG in page 182.
* The difference between ROWS and RANGE is actually similar to the difference between ROW_NUMBER and RANK, respectively. When the window ordering isn’t unique, ROWS doesn’t include peers, and therefore it isn’t deterministic, whereas RANGE includes
peers, and therefore it is deterministic. Also, the ROWS option can be optimized with an efficient in-memory spool; RANGE is optimized with an on-disk spool and therefore is usually slower.

## Chapter 6 (Querying Full-Text Data)##
* Before you start using full-text predicates and functions, you must create full-text indexes inside full-text catalogs.
* You can create full-text indexes on columns of type CHAR, VARCHAR, NCHAR, NVARCHAR, TEXT, NTEXT, IMAGE, XML, and VARBINARY(MAX). Besides using full-text indexes on SQL Server character data, you can store whole documents in binary or XML columns, and use full-text queries on those documents. Columns of data type VARBINARY(MAX), IMAGE, or XML require an additional type column in which you store the file extension (such as .docx, .pdf, or .xlsx) of the document in each row.
* You need appropriate filters for documents. Filters, called ifilters in full-text terminology, extract the textual information and remove formatting from the documents. You can check which filters are installed in your instance by using the following query. EXEC sys.sp_help_fulltext_system_components 'filter'; OR you can also query the catalog view : SELECT document_type, path FROM sys.fulltext_document_types;
* SQL Server also installs a Thesarus file (xml) for synonyms of a language. We can also edit this we if want. It uses this file to even find synonyms while using full text search.
* Exam Tip : Although full-text search is not on the list of the exam objectives, an indirect question about it could appear. Remember that full text predicates can also be a part of the WHERE clause of a query.
* After you have all of the full-text infrastructure in place, you can start using it. Full-text indexes are stored in full-text catalogs. A full-text catalog is a virtual object, a container for full-text indexes. As a virtual object, it does not belong to any filegroup.
* Semantic search gives you the possibility to create your own text-mining solution. Semantic search could be especially interesting in conjunction with text-mining components of SQL Server Integration Services (SSIS).  In order to use the Semantic Search feature, you have to have Full-Text Search installed. In addition, you need to install the Semantic Language Statistics Database.
* SQL Server supports two very powerful predicates for limiting the result set of a query by using full-text indexes. These two predicates are the CONTAINS and FREETEXT predicates. Both of them support various term searching. Besides these two predicates, SQL Server supports two table-valued functions for full-text searches, and three table-valued functions for semantic searches.
* The FREETEXT predicate is less specific and thus returns more rows than the CONTAINS predicate. It searches for the values that match the meaning of a phrase and not just exact words. When you use the FREETEXT predicate, the engine performs word breaking of the search phrase, generates inflectional forms (does the stemming), and identifies a list of expansions or replacements for the words in the searched term with words from the thesaurus.
* Full-text catalogs and indexes are not stored in a SQL Server database. Full-text catalogs and indexes are stored in separate files that the Microsoft Search service manages. The full-text catalog files are not recovered during a Microsoft SQL Server recovery. Additionally, you cannot use the Transact SQL statements BACKUP and RESTORE to back up and to restore full-text catalog files. After recovery or restore operations, you must separately resynchronize the full-text catalogs. Only the Microsoft Windows NT system administrator and the Microsoft Search service can access the full-text catalog files.
* Terms in a full-text search can be weighted to change the rank of documents. However, you cannot see the rank by using the CONTAINS predicate. You need to get a table of documents (or document IDs) and their rank. This table is returned by the CONTAINSTABLE and FREETEXTTABLE functions. We can also do semantic search through three table-valued functions: SEMANTICKEYPHRASETABLE, SEMANTICSIMILARITYDETAILSTABLE, and SEMANTICSIMILARITYTABLE.
* The CONTAINSTABLE and FREETEXTTABLE functions return two columns: KEY and RANK. The KEY column is the unique key from the index used in the KEY INDEX clause of the CREATE FULLTEXT INDEX statement. RANK returns an ordinal value between 0 and 1000. This is the rank value. It tells you how well a row matches your search criteria. The number is always relative to a query; it tells you only relative order of relevance for a particular rowset. A lower value means lower relevance. The actual values are not important; they might even change when you run the same query next time.
* 'Check Suggested' Practices Section in page no: 215.

## Chapter 7 (Querying and Managing XML Data)##

* SQL Server 2012 includes extensive support for XML. This support includes creating XML from relational data with a query and shredding XML into relational tabular format. Additionally, SQL Server has a native XML data type. You can store XML data, constrain it with XML schemas, index it with specialized XML indexes, and manipulate it using XML data type methods. All of the T-SQL XML data type methods accept an XQuery string as a parameter. XQuery (short for XML Query Language) is the standard language used to query and manipulate XML data.
* XML is a widely used standard for data exchange, calling web services methods, configuration files, and more.
* XML uses tags to name parts of an XML document. These parts are called elements. Every begin tag, such as <Customer>, must have a corresponding end tag, in this case </Customer>. If an element has no nested elements, the notation can be abbreviated to a single tag that denotes the beginning and end of an element, such as <Order [corresponding data here] />. Elements can be nested. Tags cannot be interleaved; the end tag of a parent element must be after the end tag of the last nested element. If every begin tag has a corresponding end tag, and if tags are nested properly, the XML document is well-formed.
* XML documents are ordered (same order as they are in the tags). 
* XML is case-sensitive Unicode text. You should never forget that XML is case sensitive. In addition, some characters in XML, such as <, which introduces a tag, are processed as markup and have special meanings. If you want to include these characters in the values of your XML document, they must be escaped by using an ampersand (&), followed by a special code, followed by a semicolon (;). Example if we want to use < symbol in the data, we need to use &lt; if we use < instead, XML will think of it as a beginning of a new tag. Alternatively, you can use the special XML CDATA section, written as <![CDATA[...]]>. You can replace the three dots with any character string that does not include the string literal "]]>"; this will prevent special characters in the string from being parsed as XML markup.
* Processing instructions, which are information for applications that process XML, are written similarly to elements, between less than (<) and greater than (>) characters, and they start and end with a question mark (?), like <?PItarget data?>. The engine that processes XML—for example, the SQL Server Database Engine — receives those instructions.
* XML can include comments in the format <!-- This is a comment -->.
* XML DOCUMENT has single root node Example: <tag1> <tag2></tag2> <tag2></tag2> <tag1>. here <tag1> is the root node and it has only one entry. If you remove the root node from above example, it becomes, <tag2></tag2> <tag2></tag2> here, root node is tag2 but it comes twice. so this is an example of XML FRAGMENT. Now, if you remove one tag2 from above fragment, it becomes <tag2></tag2>. Now, this is again an example for XML Document because it only has one entry of root node which is tag2.
* The tags are called elements. Elements can have attributes. Attributes have their own names, and their values are enclosed in quotation marks. This is attribute-centric presentation. However, you can write XML differently; every attribute can be a nested element of the original element. This is element-centric presentation.
* XML can have a prolog at the beginning of the document, denoting the XML version and encoding of the document, such as <?xml version="1.0" encoding="ISO-8859-15"?>.
* Element names do not have to be unique, because they can be referred to by their position; however, to distinguish between elements from different business areas, different departments, or different companies, you can add namespaces. You declare namespaces used in the root element of an XML document. You can also use an alias for every single namespace. Then you prefix element names with a namespace alias.
* Because XML is text, it is very convenient for exchanging data between different systems and even between different platforms. However, when exchanging data, it becomes important to have metadata fixed. Many different standards have evolved to describe the metadata of XML documents. Currently, the most widely used metadata description is with XML Schema Description (XSD) documents. XSD documents are XML documents that describe the metadata of other XML documents. The schema of an XSD document is predefined. With the XSD standard, you can specify element names, data types, and number of occurrences of an element, constraints, and more.
* 




