#Day 1#
* 'Repository Service' helps the repository to interact with the other Client Components (Storing to repository and send the information to Other Client Components). This helps in Saving the Program
* 'Integration Service' helps in execution of ETL. THis helps n Executing the Program.
* The Client tools will interact with Server Components (repository/Integration Services and Repository) Using TCP/IP Protocol. Check what TCP/IP Protocol means.
* One Installation on Server is called NODE. To Improve Availability, We can install Informatica on Multiple Nodes. All the Nodes will Access the SAME Repository. DOMAIN is a Collection of NODES.
* GATEWAY NODE is UNIQUE in a DOMAIN. When ever a request comes to Informatica DOMAIN, it will first go to GATEWAY NODE. This Node will share the LOAD with other WORKER NODES based on Load.
* Changes from 8x to 9x: 1)Components packaged together 2)LKP Now can take All Matches and Increase the Output Rows (Earlier it was like SSIS (picks first (Or Last Match if configured))) 3) Dynamic Lookup Cache 4) Session Log Rotation (so No need to handle Log Clean-up now).
* Partitioning : Executing the JOB in Parallel (Dont get confused with DB Partitioning, its totally Different) partitions. Whenever we run a Mapping, Three Threads will be created (Source, Transformation, Target) one Source-Transformation-Target threads combination is called a Partition. When load is more. Example, 10 Million rows, instead of using 1 partition we can configure Infromatica to use Five partitions of 2 million records each, to run in parallel and produce better performance. 'Partition' Option will be available in MAPPING Tab of Session Properties. We can also give Queries to Partitions so that those partitions will pick only data filtered through that query. Dis advantage of partitions in that each partition will create a new Thread on the NODE and new threads can cause a bottle neck since a NODE can run only N number of threads at one point in time. 
* Partition Types are : Pass through, Key Partition and Database Partitioning. 'Pass through' is default (write SQL Quwery to deternime what data goes to that partition). 'Key partition' will allow us to specify the range that goes into a partition using some key value. 'Database Partitioning' Option makes use of Partition available on DB Table and proceed accordingly. In This case, we need the create N number of partitions in Mapping Properties, if there are N number of partitions on DB table. If partitions on DB table are more, informatica will assign one of the existing partition to run the extra partition (sharing). If partitions on the Informatica Mapping are more, then it ignores the Extra partitions and does not use them. Database Partioning on TARGET  is not supported if Target is in ORACLE but it is supported if Target is in DB2. So, we should check compatibility before choosing Database Partitioning option. 
* 'Round Robin'  and 'Hash key' partitions. Check these in google/informatica HELP. Also, DYNAMIC partitioning options are available on 'Config Object' tab of Session Properties.
* Versioning should be configured while configuring the Repository. Versioning is Linked to Repository.
* Deployment Options (1. Import/Export 2. Folder Copy 3. Deployment Group). 1: Export from a Source Repository and Import to a Target Repository. This is useful if you are moving only one component of your project to QA 2: Copy folder from one place to other? 3: Create a Group in 'Deployment Group' Folder of Repository and just Drag and Drop your code to the Group. Deployment Group Creation can be done in 2 ways Static and Dynamic. Static will need us to Drag and Drop code to the Depoyment group folder. Dynamic means, we need to write a query and based on that query , the code will automatically mode to the Created Deployment Group.
* Things to consider during Migration (1: Shell Scripts, 2: Connections, 3: DML and DDL)
* In Lookup Transformation, we can choose the Option 'Enable Caching' so that the data will be cached to a file on the Informatic Server (Similar to CAW files in SSIS). This is useful when the Lookup is HUGE. 'Dynamic Lookup' option, if enabled, will generate a 'New Lookup' Port. Based on this New Lookup Port, Cache will be updated automaticaly. Also Check about Index Cache and Data Cache in google/Informatica Help. 'Persistent Cache' option is used if we want to use the cache somewhere else. 
* 
* 
